{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGbm/t8NIlZB+2w0X2upAd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandana-galgali/PRODIGY_ML_04/blob/main/Task04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFBddWlCTEjm"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "# Define dataset path inside Google Drive\n",
        "dataset_path = \"/content/drive/My Drive/leapGestRecog\"  # Change this to the correct path in your Google Drive\n",
        "\n",
        "# Data Augmentation and Preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Load dataset from directory\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=img_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=img_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\"\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=img_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "# Build CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=15,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "# Save Model inside Google Drive\n",
        "model.save(\"/content/drive/My Drive/hand_gesture_model.h5\")\n",
        "print(\"Model saved to Google Drive.\")\n",
        "\n",
        "# Display Model Summary\n",
        "model.summary()\n",
        "\n",
        "# Plot Training History\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training vs Validation Loss')\n",
        "\n",
        "plt.show()"
      ]
    }
  ]
}